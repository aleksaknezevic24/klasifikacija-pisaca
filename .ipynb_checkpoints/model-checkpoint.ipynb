{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Embedding, concatenate\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(max_words):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(500,)))\n",
    "    model.add(Embedding(len(max_words)+1, 50))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(Bidirectional(LSTM(100, recurrent_activation=\"sigmoid\", activation='tanh',\n",
    "                    unroll = False,\n",
    "                    dropout = 0.3,\n",
    "                    use_bias = True,\n",
    "                    return_sequences = True,\n",
    "                    recurrent_dropout=0)))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size = 8, padding = \"same\"))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size = 8, padding = \"same\"))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(512, kernel_size = 8, padding = \"same\"))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(512, kernel_size = 8, padding = \"same\"))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(0.08))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=1e-3),metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "    \"\"\"\n",
    "    embedding_layer = Embedding(len(max_words)+1, 50)\n",
    "    sequence_input = Input(shape=(500,))\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = SpatialDropout1D(0.2)(embedded_sequences)\n",
    "    \n",
    "    x = Bidirectional(LSTM(100, recurrent_activation=\"sigmoid\", activation='tanh',\n",
    "                    unroll = False,\n",
    "                    dropout = 0.3,\n",
    "                    use_bias = True,\n",
    "                    return_sequences = True,\n",
    "                    recurrent_dropout=0))(x)\n",
    "\n",
    "    x = Conv1D(128, kernel_size = 5, padding = \"same\", activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Conv1D(256, kernel_size = 5, padding = \"same\", activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Conv1D(512, kernel_size = 5, padding = \"same\", activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Dropout(0.5)(x) \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool]) \n",
    "    x = Dense(256, activation=\"relu\", kernel_initializer='he_uniform') (x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_initializer='he_uniform') (x)\n",
    "    preds = Dense(2, activation='softmax')(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=1e-3),metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stari_model(max_words):\n",
    "    text_input_layer = Input(shape=(500,))\n",
    "    embedding_layer = Embedding(len(max_words)+1, 50)(text_input_layer)\n",
    "    text_layer = Conv1D(64, 3, activation='relu')(embedding_layer)\n",
    "    text_layer = MaxPooling1D(4)(text_layer)\n",
    "    text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "    text_layer = Conv1D(128, 3, activation='relu')(text_layer)\n",
    "    text_layer = MaxPooling1D(4)(text_layer)\n",
    "    text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "    text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "    text_layer = MaxPooling1D(3)(text_layer)\n",
    "    text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "    text_layer = Conv1D(512, 3, activation='relu')(text_layer)\n",
    "    text_layer = MaxPooling1D(3)(text_layer)\n",
    "    text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "    text_layer = GlobalMaxPooling1D()(text_layer)\n",
    "    text_layer = Dense(256, activation='relu')(text_layer)\n",
    "    output_layer = Dense(2, activation='softmax')(text_layer)\n",
    "    model = Model(text_input_layer, output_layer)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
