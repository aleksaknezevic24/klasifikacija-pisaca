{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "df1 = pd.read_csv(\"pisci.csv\")\n",
    "df1.rename(columns={ '0':'tekst', '1':'pisac'}, \n",
    "                 inplace=True)\n",
    "\n",
    "#funkcija sample sluzi za nasumicno mesanje samplova  \n",
    "df1 = df1.sample(frac=1)\n",
    "df1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tekst</th>\n",
       "      <th>pisac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>tumači posvetili potrebnu pažnju sudeći po bib...</td>\n",
       "      <td>andric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>se na odstojanju i mene držiš na odstojanju do...</td>\n",
       "      <td>selimovic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>pa dobro da te poslusam a doktore ne zovi pust...</td>\n",
       "      <td>selimovic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>mostova na levoj obali drine i na desnoj obali...</td>\n",
       "      <td>andric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>telo zaobilazeći krv kojaje curila sa mesta gd...</td>\n",
       "      <td>andric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tekst      pisac\n",
       "953  tumači posvetili potrebnu pažnju sudeći po bib...     andric\n",
       "567  se na odstojanju i mene držiš na odstojanju do...  selimovic\n",
       "817  pa dobro da te poslusam a doktore ne zovi pust...  selimovic\n",
       "140  mostova na levoj obali drine i na desnoj obali...     andric\n",
       "165  telo zaobilazeći krv kojaje curila sa mesta gd...     andric"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.random.set_seed(1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63469 unique tokens. \n",
      "Data Shape: (1650, 500)\n"
     ]
    }
   ],
   "source": [
    "# sece na maksimalno 500 karaktera po sample-u\n",
    "max_len = 500 \n",
    "# razmatra prvih 10 000 reci\n",
    "max_words = 10000 \n",
    "\n",
    "lista = df1['tekst'].to_list()\n",
    "\n",
    "# import tokenizer, gleda se samo prvih 10 000 reci\n",
    "tokenizer = Tokenizer(num_words=max_words) \n",
    "# fitujemo tokenizer na listu tekstova\n",
    "tokenizer.fit_on_texts(lista) \n",
    "# konvertujemo tekst u sekvence\n",
    "sekvence = tokenizer.texts_to_sequences(lista) \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens. ' % len(word_index))\n",
    "\n",
    " # pravimo array sekvenci sa maksimalnom duzinom 500 \n",
    "data = pad_sequences(sekvence, maxlen=max_len)\n",
    "print('Data Shape: {}'.format(data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 500) int32\n",
      "(1650, 2) uint8\n"
     ]
    }
   ],
   "source": [
    "pisac_enkoder = OneHotEncoder()\n",
    "#ubacujemo data u promenjivu X\n",
    "X = np.array(data)\n",
    "\n",
    "#binarizujemo pisce, koji su kategoricki nominalni tip\n",
    "y = pd.get_dummies(df1['pisac'])\n",
    "#uzimamo nazive kolona kako bismo posle mogli da vratimo prezimena pisaca\n",
    "kolone = list(y.columns.values)\n",
    "#print(kolone)\n",
    "\n",
    "y = y.to_numpy()\n",
    "\n",
    "#printamo shape od X i y\n",
    "print(X.shape, X.dtype)\n",
    "print(y.shape, y.dtype)\n",
    "\n",
    "#delimo podatke na trening i test, gde 25% ide na test a ostalo na trening\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 500, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 498, 256)          38656     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 166, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 166, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 164, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 54, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 52, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,392,418\n",
      "Trainable params: 1,392,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input_layer = keras.Input(shape=(500,))\n",
    "embedding_layer = Embedding(max_words, 50)(text_input_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(embedding_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Dropout(0.5)(text_layer)\n",
    "\n",
    "text_layer = GlobalMaxPooling1D()(text_layer)\n",
    "text_layer = Dense(256, activation='relu')(text_layer)\n",
    "output_layer = Dense(2, activation='softmax')(text_layer)\n",
    "model = Model(text_input_layer, output_layer)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 7s 719ms/step - loss: 0.6885 - acc: 0.5740\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 7s 668ms/step - loss: 0.6786 - acc: 0.5764\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 7s 665ms/step - loss: 0.6560 - acc: 0.5772\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 7s 651ms/step - loss: 0.5366 - acc: 0.6500\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.3620 - acc: 0.8868\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 6s 635ms/step - loss: 0.1879 - acc: 0.9806\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 0.0190 - acc: 0.9919\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 7s 677ms/step - loss: 3.1603e-04 - acc: 1.0000\n",
      "Epoch 9/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8533e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=128, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "# Uzimamo poslednjih 5 vrsti\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred1 = np.argmax(y_pred,axis=1)\n",
    "y_test1 = np.argmax(y_test,axis=1)\n",
    "print('Preciznost: %.3f' % precision_score(y_true=y_test1, y_pred = y_pred1))\n",
    "print('Recall skor: %.3f' % recall_score(y_true=y_test1, y_pred = y_pred1))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test1, y_pred = y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dummies_pred = pd.get_dummies(kolone)\n",
    "\n",
    "y_pred = pd.DataFrame(data=y_pred, columns=kolone)\n",
    "y_test = pd.DataFrame(data=y_test, columns=kolone)\n",
    "y_pred = y_pred.idxmax(axis=1)\n",
    "y_test = y_test.idxmax(axis=1)\n",
    "\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"MATRICA KOFUZIJE\")\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "promasen_tekst = X_test[y_test != y_pred]\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "#promasen_tekst = decoded_review\n",
    "tacan_pisac = y_test[y_test != y_pred]\n",
    "promasen_pisac = y_pred[y_test != y_pred]\n",
    "duzine = [len(promasen_pisac), len(tacan_pisac), len(promasen_tekst), 5]\n",
    "\n",
    "for i in range(min(duzine)):\n",
    "    promasen_tekst1 = ' '.join([reverse_word_index.get(kljuc, '') for kljuc in promasen_tekst[i]])\n",
    "    print(promasen_tekst1)\n",
    "    print(\"Promasen pisac: {}\".format(promasen_pisac[i]))\n",
    "    print(\"Tacan pisac: {}\".format(tacan_pisac[i]))\n",
    "    print(\"\")\n",
    "\n",
    "if(min(duzine) == 0):\n",
    "    print(\"Nema ni jednog promasaja.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#REFERENCA: https://medium.com/@romannempyre/sentiment-analysis-using-1d-convolutional-neural-networks-part-1-f8b6316489a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_pisci.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
